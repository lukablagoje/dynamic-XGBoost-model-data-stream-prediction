{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014282,
     "end_time": "2023-06-03T01:46:16.695936",
     "exception": false,
     "start_time": "2023-06-03T01:46:16.681654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Submission Pipeline\n",
    "In the section below, the hyperparameters obtained in the first part are utilized for the model, which is trained and used for dynamic price prediction (the data stream is provided in the competition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-24T01:16:30.479757Z",
     "iopub.status.busy": "2023-09-24T01:16:30.479022Z",
     "iopub.status.idle": "2023-09-24T01:16:30.898036Z",
     "shell.execute_reply": "2023-09-24T01:16:30.896938Z",
     "shell.execute_reply.started": "2023-09-24T01:16:30.479686Z"
    },
    "papermill": {
     "duration": 4.795021,
     "end_time": "2023-06-03T01:46:36.791162",
     "exception": false,
     "start_time": "2023-06-03T01:46:31.996141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Loading the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import KNNImputer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up the data types\n",
    "dtypes = {\n",
    "    'stock_id' : np.float32,\n",
    "    'date_id' : np.uint16,\n",
    "    'seconds_in_bucket' : np.uint16,\n",
    "    'imbalance_buy_sell_flag' : np.int8,\n",
    "    'time_id' : np.uint16,\n",
    "}\n",
    "\n",
    "### X columns to be used\n",
    "X_columns = ['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
    "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
    "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
    "       'ask_size', 'wap','time_id']\n",
    "\n",
    "### Columns used in prediction (at this stage, all of them)\n",
    "X_predict = X_columns[:]\n",
    "\n",
    "# Target column\n",
    "y_columns = ['target']\n",
    "\n",
    "\n",
    "### Loading the data and transforming far/near price nan values (before 300 seconds in bucket)\n",
    "df = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv', dtype = dtypes).drop(['row_id'], axis = 1)\n",
    "\n",
    "df['far_price'] = df.apply(\n",
    "    lambda row: row['reference_price'] if np.isnan(row['far_price']) else row['far_price'],\n",
    "    axis=1)\n",
    "\n",
    "df['near_price'] = df.apply(\n",
    "    lambda row: row['reference_price'] if np.isnan(row['near_price']) else row['near_price'],\n",
    "    axis=1)\n",
    "\n",
    "\n",
    "\n",
    "### Removing NaN values, since there is only 200 of them\n",
    "df = df.dropna()\n",
    "\n",
    "### Removing NaN values, since there is only 200 of them\n",
    "X_current_dataset, y_current_dataset = df.loc[:,X_columns].copy(), df.loc[:,y_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the XGB Regressor model, parameters estimated by hyperparmeter optimization\n",
    "model =xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n",
    "                       n_estimators=100,\n",
    "                       objective='reg:squarederror',\n",
    "                       max_depth=3,\n",
    "                       learning_rate=0.01).fit(X_current_dataset[X_predict], y_current_dataset)\n",
    "\n",
    "### Using and fitting an imputer for the filling of NaN values in the testing set, before prediction or retraining is done\n",
    "x_imputer = KNNImputer(n_neighbors=5)\n",
    "x_imputer.fit(X_current_dataset[X_columns])\n",
    "y_imputer = KNNImputer(n_neighbors=5)\n",
    "y_imputer.fit(y_current_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counter for each iteration\n",
    "counter = 0\n",
    "\n",
    "### Counter for retraining (or a \"daily counter\")\n",
    "rt_i  = 0\n",
    "\n",
    "### Lists and dictionaries to store the data\n",
    "test_history = []\n",
    "revealed_targets_history = {}\n",
    "prediction_history = []\n",
    "sample_predictions_history = []\n",
    "\n",
    "### How many counters to skip\n",
    "n_counts_to_skip = 54\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    print('Counter:',counter)\n",
    "    if counter >n_counts_to_skip and counter%number_of_bucket_iter == 0 and len(revealed_targets) > 1 and False:\n",
    "        ### Storing the revealed targets\n",
    "        revealed_targets_history[counter] = revealed_targets\n",
    "        \n",
    "        ### The data for revealed targets that given in this itertation(i-1), corresponds to the previous day (i-1)\n",
    "        X_revealed = pd.concat(test_history[number_of_bucket_iter*rt_i:number_of_bucket_iter*(rt_i+1)])\n",
    "        y_revealed = revealed_targets_history[number_of_bucket_iter*(rt_i+1)]['revealed_target']\n",
    "        \n",
    "        ### Making sure nan values are filled (some other way should be done)\n",
    "        X_revealed = pd.DataFrame(x_imputer.transform(X_revealed[X_columns]), columns=X_columns )\n",
    "        y_revealed = pd.DataFrame(y_imputer.transform(y_revealed.to_frame().rename(columns= {'revealed_target': 'target'})),columns=y_columns)\n",
    "        \n",
    "        ### The revealed target index (rt_i) is increased by 1\n",
    "        rt_i +=1\n",
    "        \n",
    "        ### Appending the data to the entire dataset, if the date_id is not present in the current dataset\n",
    "        date_id = X_revealed['date_id'].values[0]\n",
    "        if date_id not in X_current_dataset['date_id'].values:\n",
    "            X_current_dataset = pd.concat([X_current_dataset,X_revealed]).reset_index(drop=True).copy()\n",
    "            y_current_dataset = pd.concat([y_current_dataset,y_revealed]).reset_index(drop=True).copy()\n",
    "        \n",
    "            #### Retraining the model \n",
    "            x_imputer.fit(X_current_dataset[X_columns])\n",
    "            y_imputer.fit(y_current_dataset[X_columns])\n",
    "            model.fit( X_current_dataset, y_current_dataset,\n",
    "                verbose=100,xgb_model =model.get_booster())\n",
    "                \n",
    "    ### Dealing with null values of the current iteration of the test data\n",
    "    test.loc[:,'far_price']= test.apply(lambda row: row['reference_price']  if np.isnan(row['far_price']) else row['far_price'],axis=1)\n",
    "    test.loc[:,'near_price'] =test.apply(lambda row: row['reference_price']  if np.isnan(row['near_price']) else row['near_price'],axis=1)\n",
    "    test.loc[:,'time_id'] = test.apply(lambda row: int(55 * row['date_id'] + row['seconds_in_bucket']/10),axis=1)\n",
    "    \n",
    "    ### Using the imputer to deal with potential missing values in X_test\n",
    "    X_test = test[X_columns]\n",
    "    #X_test['target_class'] = model_target_class.predict(test[X_columns])\n",
    "    X_test = pd.DataFrame(x_imputer.transform(X_test),columns = X_columns)\n",
    "\n",
    "    ### Creating the prediction column by using the current iteration of test data\n",
    "    sample_prediction['target'] = 0\n",
    "    if counter > n_counts_to_skip:#164:\n",
    "        sample_prediction['target'] = model.predict(X_test[X_predict])\n",
    "        \n",
    "    ### Storing the current iteration of the data in the lists\n",
    "    test_history.append(X_test)\n",
    "    prediction_history.append(sample_prediction)\n",
    "    \n",
    "    ### Submiting the prediction\n",
    "    env.predict(sample_prediction)\n",
    "    \n",
    "    #Movin the iter counter\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
